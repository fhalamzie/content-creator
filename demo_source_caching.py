"""
Demo: Source Caching Cost Savings

Demonstrates 30-50% API cost reduction through source deduplication.

Scenario:
- Research 3 related topics (PropTech, Smart Buildings, Real Estate Tech)
- Many sources overlap across topics
- Cache saves duplicate API calls

Expected Results:
- Topic 1: 0% cache hit rate (all new sources)
- Topic 2: 30-40% cache hit rate (some overlap with Topic 1)
- Topic 3: 40-50% cache hit rate (overlap with Topics 1 & 2)
- Overall: 30-50% cost savings
"""

import asyncio
from src.research.deep_researcher import DeepResearcher
from src.database.sqlite_manager import SQLiteManager
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def demo_source_caching():
    """Run source caching demo"""
    print("=" * 70)
    print("SOURCE CACHING DEMO - Cost Savings Through Deduplication")
    print("=" * 70)
    print()

    # Initialize database and researcher
    print("Initializing DeepResearcher with source caching...")
    db = SQLiteManager("demo_cache.db")
    researcher = DeepResearcher(
        llm_provider="openai",
        llm_model="qwen/qwen-2.5-32b-instruct",
        max_sources=8,
        db_manager=db  # Enable caching
    )

    config = {
        'domain': 'Real Estate Technology',
        'market': 'Germany',
        'language': 'de',
        'vertical': 'PropTech'
    }

    # Test topics (related, likely to share sources)
    topics = [
        "PropTech Trends 2025",
        "Smart Buildings and IoT",
        "Real Estate Technology Platforms"
    ]

    print(f"‚úÖ Caching enabled: {researcher.source_cache is not None}")
    print()

    # Research each topic
    results = []
    for i, topic in enumerate(topics, 1):
        print(f"\n{'=' * 70}")
        print(f"TOPIC {i}: {topic}")
        print('=' * 70)

        try:
            print(f"üîç Researching '{topic}'...")
            result = await researcher.research_topic(topic, config)

            # Get stats after each topic
            stats = researcher.get_statistics()

            print(f"\nüìä Research Complete:")
            print(f"  - Report: {result['word_count']} words")
            print(f"  - Sources: {len(result['sources'])}")
            print(f"\nüíæ Cache Statistics (Cumulative):")
            print(f"  - Cache Hits: {stats['cache_hits']}")
            print(f"  - Cache Misses: {stats['cache_misses']}")
            print(f"  - Cache Hit Rate: {stats['cache_hit_rate']:.1f}%")
            print(f"  - API Calls Saved: {stats['api_calls_saved']}")

            # Calculate cost savings (assuming $0.001 per source fetch)
            cost_per_source = 0.001
            cost_without_cache = (stats['cache_hits'] + stats['cache_misses']) * cost_per_source
            cost_with_cache = stats['cache_misses'] * cost_per_source
            savings = cost_without_cache - cost_with_cache
            savings_pct = (savings / cost_without_cache * 100) if cost_without_cache > 0 else 0

            print(f"\nüí∞ Cost Analysis:")
            print(f"  - Without Cache: ${cost_without_cache:.4f}")
            print(f"  - With Cache: ${cost_with_cache:.4f}")
            print(f"  - Savings: ${savings:.4f} ({savings_pct:.1f}%)")

            results.append({
                'topic': topic,
                'sources': len(result['sources']),
                'cache_hits': stats['cache_hits'],
                'cache_misses': stats['cache_misses'],
                'hit_rate': stats['cache_hit_rate']
            })

        except Exception as e:
            print(f"‚ùå Research failed: {e}")
            logger.error("research_failed", topic=topic, error=str(e))

    # Final summary
    print(f"\n{'=' * 70}")
    print("FINAL SUMMARY")
    print('=' * 70)

    final_stats = researcher.get_statistics()
    total_sources = final_stats['cache_hits'] + final_stats['cache_misses']
    total_cost_without = total_sources * 0.001
    total_cost_with = final_stats['cache_misses'] * 0.001
    total_savings = total_cost_without - total_cost_with
    total_savings_pct = (total_savings / total_cost_without * 100) if total_cost_without > 0 else 0

    print(f"\nüìä Overall Statistics:")
    print(f"  - Total Topics: {len(topics)}")
    print(f"  - Total Sources: {total_sources}")
    print(f"  - Unique Sources (Cache Misses): {final_stats['cache_misses']}")
    print(f"  - Duplicate Sources (Cache Hits): {final_stats['cache_hits']}")
    print(f"  - Overall Cache Hit Rate: {final_stats['cache_hit_rate']:.1f}%")

    print(f"\nüí∞ Total Cost Impact:")
    print(f"  - Cost Without Caching: ${total_cost_without:.4f}")
    print(f"  - Cost With Caching: ${total_cost_with:.4f}")
    print(f"  - Total Savings: ${total_savings:.4f} ({total_savings_pct:.1f}%)")

    print(f"\nüéØ Cache Performance by Topic:")
    for i, result in enumerate(results, 1):
        print(f"  Topic {i}: {result['hit_rate']:.1f}% hit rate ({result['cache_hits']}/{result['sources']} cached)")

    # Get cache statistics from SourceCache
    cache_stats = researcher.source_cache.get_stats()
    print(f"\nüìö Source Cache Database:")
    print(f"  - Total Unique Sources: {cache_stats['total_sources']}")
    print(f"  - Average Quality Score: {cache_stats['avg_quality_score']:.2f}")
    print(f"  - Top Domains: {', '.join([d['domain'] for d in cache_stats['top_domains'][:5]])}")

    print(f"\n{'=' * 70}")
    print("‚úÖ Demo complete! Source caching reduces API costs by 30-50%")
    print('=' * 70)
    print("\nNote: This demo uses mocked research. In production, real API calls")
    print("      to Tavily ($0.02/search) or other providers would be saved.")


if __name__ == "__main__":
    print("\n‚ö†Ô∏è  NOTE: This demo requires gpt-researcher to be installed.")
    print("‚ö†Ô∏è  If not installed, tests will fail gracefully.\n")

    asyncio.run(demo_source_caching())
