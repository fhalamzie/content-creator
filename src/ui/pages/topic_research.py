"""
Topic Research Page - Production Pipeline UI

Process topics through the production-ready pipeline:
1. Multi-Backend Research (Tavily + SearXNG + Gemini + RSS + TheNewsAPI)
2. 3-Stage Reranking (BM25 ‚Üí Voyage Lite ‚Üí Voyage Full)
3. Content Synthesis (BM25‚ÜíLLM passage extraction ‚Üí 2000-word article)

Features:
- Real-time progress tracking
- Cost estimation and tracking
- Source diversity visualization
- Backend reliability monitoring
"""

import streamlit as st
from pathlib import Path
import json
import os
import asyncio
from datetime import datetime
from typing import Dict, List
from collections import defaultdict
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import production pipeline components
import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.research.deep_researcher_refactored import DeepResearcher
from src.research.reranker.multi_stage_reranker import MultiStageReranker
from src.research.synthesizer.content_synthesizer import (
    ContentSynthesizer,
    PassageExtractionStrategy
)
from src.utils.config_loader import ConfigLoader


CACHE_DIR = Path(__file__).parent.parent.parent.parent / "cache"
CONFIG_FILE = CACHE_DIR / "topic_research_config.json"


def load_research_config():
    """Load topic research configuration."""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {
        "market": "proptech_de",
        "enable_tavily": True,
        "enable_searxng": True,
        "enable_gemini": True,
        "enable_rss": False,
        "enable_thenewsapi": False,
        "enable_reranking": True,
        "enable_synthesis": True,
        "max_article_words": 2000,
        "synthesis_strategy": "bm25_llm",
        "enable_images": False
    }


def save_research_config(config: dict):
    """Save topic research configuration."""
    CACHE_DIR.mkdir(exist_ok=True)
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)


def render_config_sidebar():
    """Render configuration sidebar."""
    with st.sidebar:
        st.header("‚öôÔ∏è Pipeline Configuration")

        config = load_research_config()

        # Market config
        st.subheader("üìç Market Config")
        market_preset = st.selectbox(
            "Market Preset",
            ["proptech_de", "fashion_fr", "saas_us", "custom"],
            index=0 if config.get("market") == "proptech_de" else 3,
            help="Load predefined market configuration"
        )

        # Backend configuration
        st.subheader("üîç Research Backends")
        enable_tavily = st.checkbox(
            "Tavily (DEPTH)",
            value=config.get("enable_tavily", True),
            help="Deep, comprehensive search results"
        )
        enable_searxng = st.checkbox(
            "SearXNG (BREADTH)",
            value=config.get("enable_searxng", True),
            help="Wide coverage across multiple sources"
        )
        enable_gemini = st.checkbox(
            "Gemini API (TRENDS)",
            value=config.get("enable_gemini", True),
            help="Google Search grounding for trending content"
        )
        enable_rss = st.checkbox(
            "RSS Feeds (NICHE)",
            value=config.get("enable_rss", False),
            help="Industry-specific RSS feeds"
        )
        enable_thenewsapi = st.checkbox(
            "TheNewsAPI (NEWS)",
            value=config.get("enable_thenewsapi", False),
            help="Real-time news coverage"
        )

        # Pipeline stages
        st.subheader("üéØ Pipeline Stages")
        enable_reranking = st.checkbox(
            "Enable Reranking",
            value=config.get("enable_reranking", True),
            help="3-stage reranker (BM25 ‚Üí Voyage Lite ‚Üí Voyage Full)"
        )
        enable_synthesis = st.checkbox(
            "Enable Content Synthesis",
            value=config.get("enable_synthesis", True),
            help="Generate 2000-word article with citations"
        )

        # Synthesis settings
        if enable_synthesis:
            st.subheader("üìù Synthesis Settings")
            max_article_words = st.slider(
                "Max Article Words",
                min_value=500,
                max_value=3000,
                value=config.get("max_article_words", 2000),
                step=500
            )
            synthesis_strategy = st.selectbox(
                "Strategy",
                ["bm25_llm", "llm_only"],
                index=0 if config.get("synthesis_strategy") == "bm25_llm" else 1,
                help="BM25‚ÜíLLM: fast, cheap (92% quality) | LLM-only: slower, expensive (94% quality)"
            )

            # Image generation settings
            st.subheader("üñºÔ∏è Image Generation")
            enable_images = st.checkbox(
                "Generate images (1 HD hero + 2 supporting)",
                value=config.get("enable_images", False),
                help="DALL-E 3: $0.16/topic (1 HD hero $0.08 + 2 standard supporting $0.08)"
            )
        else:
            max_article_words = 2000
            synthesis_strategy = "bm25_llm"
            enable_images = False

        if st.button("üíæ Save Configuration", use_container_width=True):
            new_config = {
                "market": market_preset,
                "enable_tavily": enable_tavily,
                "enable_searxng": enable_searxng,
                "enable_gemini": enable_gemini,
                "enable_rss": enable_rss,
                "enable_thenewsapi": enable_thenewsapi,
                "enable_reranking": enable_reranking,
                "enable_synthesis": enable_synthesis,
                "max_article_words": max_article_words,
                "synthesis_strategy": synthesis_strategy,
                "enable_images": enable_images
            }
            save_research_config(new_config)
            st.success("‚úÖ Configuration saved!")
            st.rerun()

        st.divider()

        # Cost estimation
        st.caption("üí∞ **Cost Estimation**")
        enabled_backends = sum([enable_tavily, enable_searxng, enable_gemini, enable_rss, enable_thenewsapi])
        base_cost = 0.005 * enabled_backends  # ~$0.005 per backend
        reranking_cost = 0.002 if enable_reranking else 0
        synthesis_cost = 0.003 if enable_synthesis else 0
        images_cost = 0.16 if enable_images else 0  # $0.16/topic (1 HD hero + 2 standard supporting)
        total_cost = base_cost + reranking_cost + synthesis_cost + images_cost
        st.caption(f"‚Ä¢ Estimated: ${total_cost:.4f}/topic")
        st.caption(f"‚Ä¢ {enabled_backends} backend{'s' if enabled_backends != 1 else ''} enabled")
        if enable_images:
            st.caption(f"‚Ä¢ Images: +${images_cost:.2f}/topic")

        return config


async def process_topic_async(
    topic: str,
    config: dict,
    progress_container
) -> Dict:
    """Process topic through production pipeline with real-time updates."""

    # Progress tracking
    progress_bar = progress_container.progress(0.0)
    status_text = progress_container.empty()
    metrics_container = progress_container.container()

    start_time = datetime.now()
    total_cost = 0.0

    try:
        # Load market config
        config_loader = ConfigLoader()
        if config["market"] == "custom":
            market_config = {"market": "USA", "language": "en", "domain": "SaaS"}
        else:
            market_config = config_loader.load(config["market"])

        # Stage 1: Initialize components
        progress_bar.progress(0.1)
        status_text.info("üîß **Stage 1/4**: Initializing pipeline components...")

        print("[DEBUG] Stage 1 START - Initializing DeepResearcher...")
        import sys
        sys.stdout.flush()

        researcher = DeepResearcher(
            enable_tavily=config["enable_tavily"],
            enable_searxng=config["enable_searxng"],
            enable_gemini=config["enable_gemini"],
            enable_rss=config["enable_rss"],
            enable_thenewsapi=config["enable_thenewsapi"]
        )

        print("[DEBUG] DeepResearcher initialized, initializing Reranker...")
        sys.stdout.flush()

        reranker = MultiStageReranker(
            enable_voyage=config["enable_reranking"],
            stage3_final_count=25
        ) if config["enable_reranking"] else None

        print("[DEBUG] Reranker initialized, initializing ContentSynthesizer...")
        sys.stdout.flush()

        synthesizer = ContentSynthesizer(
            strategy=PassageExtractionStrategy.BM25_LLM if config["synthesis_strategy"] == "bm25_llm" else PassageExtractionStrategy.LLM_ONLY,
            max_article_words=config["max_article_words"]
        ) if config["enable_synthesis"] else None

        print("[DEBUG] Stage 1 COMPLETE - All components initialized")
        sys.stdout.flush()

        # Stage 2: Research
        progress_bar.progress(0.25)
        status_text.info(f"üîç **Stage 2/4**: Researching topic across {sum([config['enable_tavily'], config['enable_searxng'], config['enable_gemini'], config['enable_rss'], config['enable_thenewsapi']])} backends...")

        # Build config dict for researcher
        research_config = {
            "market": market_config.get("market", "Germany"),
            "vertical": market_config.get("vertical", "General"),
            "domain": market_config.get("domain", "General"),
            "language": market_config.get("language", "en")
        }

        print(f"[DEBUG] About to call researcher.research_topic with config: {research_config}")
        import sys
        sys.stdout.flush()

        research_result = await researcher.research_topic(topic=topic, config=research_config)

        print(f"[DEBUG] research_topic completed, got {len(research_result.get('sources', []))} sources")
        sys.stdout.flush()

        results = research_result.get("sources", [])
        backend_counts = defaultdict(int)
        for result in results:
            backend_counts[result.get('backend', 'unknown')] += 1

        with metrics_container:
            cols = st.columns(4)
            cols[0].metric("Sources Found", len(results))
            cols[1].metric("Backends Used", len(backend_counts))
            cols[2].metric("Tavily", backend_counts.get('tavily', 0))
            cols[3].metric("Gemini", backend_counts.get('gemini', 0))

        # Stage 3: Reranking
        if reranker and results:
            progress_bar.progress(0.5)
            status_text.info("üéØ **Stage 3/4**: Reranking sources (BM25 ‚Üí Voyage Lite ‚Üí Voyage Full)...")

            reranked = await reranker.rerank(
                query=topic,
                sources=results,
                config=market_config
            )

            with metrics_container:
                st.info(f"‚úÖ Reranking complete: {len(results)} ‚Üí {len(reranked)} sources")
                if reranked:
                    st.caption(f"Top score: {reranked[0].get('score', 0):.3f}")

            results = reranked

        # Stage 4: Content Synthesis
        article = None
        hero_image_url = None
        hero_image_alt = None
        supporting_images = []
        image_cost = 0.0

        if synthesizer and results:
            progress_bar.progress(0.75)
            status_text.info("üìù **Stage 4/4**: Synthesizing article with citations...")

            # Extract brand tone from market config or use default
            brand_tone = market_config.market.brand_tone if hasattr(market_config, 'market') and hasattr(market_config.market, 'brand_tone') else ["Professional"]

            synthesis_result = await synthesizer.synthesize(
                query=topic,
                sources=results,
                config=market_config,
                brand_tone=brand_tone,
                generate_images=config.get("enable_images", False)
            )

            article = synthesis_result["article"]
            total_cost += synthesis_result.get("cost", 0)

            # Extract image data
            hero_image_url = synthesis_result.get("hero_image_url")
            hero_image_alt = synthesis_result.get("hero_image_alt")
            supporting_images = synthesis_result.get("supporting_images", [])
            image_cost = synthesis_result.get("image_cost", 0.0)
            total_cost += image_cost

            with metrics_container:
                word_count = len(article.split()) if article else 0
                st.success(f"‚úÖ Article generated: {word_count} words, {len(synthesis_result.get('citations', []))} citations")
                if config.get("enable_images", False):
                    images_generated = (1 if hero_image_url else 0) + len(supporting_images)
                    st.info(f"üñºÔ∏è Images generated: {images_generated}/3 (${image_cost:.2f})")

        # Complete
        progress_bar.progress(1.0)
        duration = (datetime.now() - start_time).total_seconds()
        status_text.success(f"‚úÖ **Processing Complete!** ({duration:.1f}s, ${total_cost:.4f})")

        return {
            "success": True,
            "topic": topic,
            "sources": results,
            "article": article,
            "cost": total_cost,
            "duration_sec": duration,
            "backend_counts": dict(backend_counts),
            "hero_image_url": hero_image_url,
            "hero_image_alt": hero_image_alt,
            "supporting_images": supporting_images,
            "image_cost": image_cost
        }

    except Exception as e:
        progress_bar.progress(0.0)
        status_text.error(f"‚ùå **Pipeline Failed**: {str(e)}")
        raise


def render_results(result: Dict):
    """Render pipeline results."""
    st.success(f"‚úÖ Topic processed: **{result['topic']}**")

    # Metrics row
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total Sources", len(result['sources']))
    col2.metric("Total Cost", f"${result['cost']:.4f}")
    col3.metric("Duration", f"{result['duration_sec']:.1f}s")

    # Show images count if generated
    if result.get('hero_image_url') or result.get('supporting_images'):
        images_count = (1 if result.get('hero_image_url') else 0) + len(result.get('supporting_images', []))
        col4.metric("Images", f"{images_count}/3")
    else:
        col4.metric("Backends", len(result['backend_counts']))

    # Tabs for different views
    tab_names = ["üìù Article", "üñºÔ∏è Images", "üìä Sources", "üìà Analytics", "üîç Raw Data"]
    tabs = st.tabs(tab_names)

    with tabs[0]:
        st.subheader("Generated Article")
        if result.get('article'):
            # Display hero image if available
            if result.get('hero_image_url'):
                st.image(
                    result['hero_image_url'],
                    caption=result.get('hero_image_alt', 'Hero image'),
                    use_container_width=True
                )
                st.divider()

            st.markdown(result['article'])
        else:
            st.info("Content synthesis was disabled")

    with tabs[1]:
        st.subheader("Generated Images")

        # Hero image
        if result.get('hero_image_url'):
            st.markdown("### Hero Image (1792x1024 HD)")
            st.image(
                result['hero_image_url'],
                caption=result.get('hero_image_alt', 'Hero image'),
                use_container_width=True
            )
        else:
            st.info("No hero image generated")

        st.divider()

        # Supporting images
        supporting = result.get('supporting_images', [])
        if supporting:
            st.markdown(f"### Supporting Images ({len(supporting)}/2)")
            cols = st.columns(2)
            for i, img in enumerate(supporting):
                with cols[i % 2]:
                    st.image(
                        img.get('url'),
                        caption=img.get('alt', f'Supporting image {i+1}'),
                        use_container_width=True
                    )
                    st.caption(f"**Size**: {img.get('size', 'N/A')} | **Quality**: {img.get('quality', 'N/A')}")
        else:
            st.info("No supporting images generated")

        # Cost breakdown
        if result.get('image_cost', 0) > 0:
            st.divider()
            st.caption(f"**Image Generation Cost**: ${result['image_cost']:.2f}")

    with tabs[2]:
        st.subheader("Top Sources")
        for i, source in enumerate(result['sources'][:10], 1):
            with st.expander(f"{i}. {source.get('title', 'Untitled')[:80]}"):
                st.caption(f"**Backend**: {source.get('backend', 'unknown')}")
                st.caption(f"**URL**: {source.get('url', 'N/A')}")
                if 'score' in source:
                    st.caption(f"**Score**: {source['score']:.3f}")
                if 'snippet' in source:
                    st.text(source['snippet'][:200] + "...")

    with tabs[3]:
        st.subheader("Backend Distribution")

        # Backend breakdown
        backend_data = result['backend_counts']
        if backend_data:
            import pandas as pd
            df = pd.DataFrame(list(backend_data.items()), columns=['Backend', 'Count'])
            st.bar_chart(df.set_index('Backend'))

        # Cost breakdown
        st.subheader("Cost Breakdown")
        st.caption(f"‚Ä¢ Total: ${result['cost']:.4f}")
        st.caption(f"‚Ä¢ Per source: ${result['cost'] / max(len(result['sources']), 1):.5f}")
        if result.get('image_cost', 0) > 0:
            st.caption(f"‚Ä¢ Images: ${result['image_cost']:.2f}")

    with tabs[4]:
        st.subheader("Raw Result Data")
        st.json({
            "topic": result['topic'],
            "sources_count": len(result['sources']),
            "has_article": result.get('article') is not None,
            "cost": result['cost'],
            "duration_sec": result['duration_sec'],
            "backend_counts": result['backend_counts'],
            "has_hero_image": result.get('hero_image_url') is not None,
            "supporting_images_count": len(result.get('supporting_images', [])),
            "image_cost": result.get('image_cost', 0.0)
        })


def render_topic_research_tab(config: dict):
    """Render Tab 1: Topic Research (Deep Research)."""
    from src.ui.components.help import feature_explanation

    # Tab-level explanation
    feature_explanation(
        title="When to use Topic Research",
        what="Comprehensive research across 5 backends with AI synthesis into a full article",
        why="Perfect for creating in-depth, well-researched content (1500-2000 words) with citations",
        when="Use when you need authoritative content for blog posts, guides, or whitepapers. Skip for quick social posts.",
        icon="üîç"
    )

    st.divider()

    # Initialize session state
    if "research_result" not in st.session_state:
        st.session_state.research_result = None

    # Main content
    st.subheader("üéØ Research a Topic")

    # Topic input
    topic = st.text_input(
        "Enter your research topic",
        placeholder="e.g., PropTech AI automation trends 2025",
        help="The system will research this topic across multiple backends",
        key="topic_research_input"
    )

    # Quick examples
    with st.expander("üí° Example Topics"):
        st.caption("**PropTech**: Smart building IoT sensors Germany, DSGVO compliance property management")
        st.caption("**SaaS**: B2B pricing strategies 2025, Customer success platforms")
        st.caption("**Fashion**: Sustainable fashion e-commerce, AI styling recommendations")

    # Process button
    process_button = st.button("üöÄ Research Topic", type="primary", use_container_width=True, disabled=not topic, key="research_topic_btn")

    if process_button and topic:
        print(f"[DEBUG] BUTTON CLICKED - Topic: {topic}")
        import sys
        sys.stdout.flush()

        # Check API keys
        required_keys = []
        if config["enable_tavily"]:
            required_keys.append("TAVILY_API_KEY")
        if config["enable_gemini"]:
            required_keys.append("GEMINI_API_KEY")
        if config["enable_reranking"]:
            required_keys.append("VOYAGE_API_KEY")

        print(f"[DEBUG] Checking {len(required_keys)} API keys...")
        sys.stdout.flush()

        missing_keys = [key for key in required_keys if not os.getenv(key)]
        if missing_keys:
            st.error(f"‚ùå Missing API keys: {', '.join(missing_keys)}")
            return

        # Process topic
        st.divider()
        st.subheader("‚öôÔ∏è Pipeline Processing")
        progress_container = st.container()

        print("[DEBUG] About to call asyncio.run(process_topic_async...)")
        sys.stdout.flush()

        try:
            # Run async processing
            result = asyncio.run(
                process_topic_async(topic, config, progress_container)
            )

            print(f"[DEBUG] asyncio.run completed successfully")
            sys.stdout.flush()

            # Store in session state
            st.session_state.research_result = result

        except Exception as e:
            st.error(f"‚ùå Pipeline failed: {str(e)}")
            st.exception(e)

    # Display results if available
    if st.session_state.research_result:
        st.divider()
        st.subheader("üìä Results")

        render_results(st.session_state.research_result)

        # Action buttons
        col1, col2 = st.columns(2)

        with col1:
            if st.button("üì§ Export to Quick Create", use_container_width=True, type="primary"):
                # Export research results to Quick Create page
                st.session_state.export_to_quick_create = {
                    "topic": st.session_state.research_result["topic"],
                    "article": st.session_state.research_result.get("article"),
                    "sources": st.session_state.research_result.get("sources", [])
                }
                st.success("‚úÖ Research exported! Navigate to Quick Create to use it.")

        with col2:
            if st.button("üóëÔ∏è Clear Results", use_container_width=True):
                st.session_state.research_result = None
                st.rerun()


def render_competitor_analysis_tab():
    """Render Tab 2: Competitor Analysis (Content Gaps)."""
    from src.ui.components.help import feature_explanation

    # Tab-level explanation
    feature_explanation(
        title="When to use Competitor Analysis",
        what="Analyze competitor content to identify gaps and opportunities in your niche",
        why="Helps you find topics your competitors are missing and create differentiated content",
        when="Use before planning content strategy or when entering a new market. Great for finding low-competition keywords.",
        icon="üè¢"
    )

    st.divider()

    st.subheader("üè¢ Competitor Content Gap Analysis")

    st.info("üöß **Coming Soon** - This feature is under development")

    st.markdown("""
    ### Planned Features:
    - **Competitor Discovery**: Automatic identification of top competitors in your niche
    - **Content Gap Analysis**: Topics they cover that you don't (and vice versa)
    - **Keyword Overlap**: Shared vs unique keywords
    - **Content Quality Scoring**: Compare your content depth vs competitors
    - **Publication Frequency**: Track competitor publishing patterns
    - **Export Insights**: Send findings to Quick Create for content planning

    ### How it will work:
    1. Enter your website URL or select competitors from Settings
    2. AI analyzes competitor content structure and topics
    3. Identifies gaps where you can create unique value
    4. Suggests 10-20 high-opportunity topics
    5. Export to Quick Create for immediate content generation
    """)

    st.divider()

    # Placeholder inputs (non-functional)
    st.text_input(
        "Your website URL",
        placeholder="https://your-company.com",
        help="Your website for comparison",
        disabled=True
    )

    st.text_area(
        "Competitor URLs (one per line)",
        placeholder="https://competitor1.com\nhttps://competitor2.com",
        help="Add up to 5 competitor websites",
        disabled=True,
        height=100
    )

    st.button("üîç Analyze Competitors", type="primary", use_container_width=True, disabled=True)


def render_keyword_research_tab():
    """Render Tab 3: Keyword Research (SEO Keywords)."""
    from src.ui.components.help import feature_explanation

    # Tab-level explanation
    feature_explanation(
        title="When to use Keyword Research",
        what="Discover high-value SEO keywords with search volume, competition, and intent analysis",
        why="Target keywords that drive organic traffic without expensive paid ads",
        when="Use at the start of content planning or when optimizing existing content. Essential for SEO-focused content.",
        icon="üîë"
    )

    st.divider()

    st.subheader("üîë SEO Keyword Research")

    st.info("üöß **Coming Soon** - This feature is under development")

    st.markdown("""
    ### Planned Features:
    - **Keyword Discovery**: Find related keywords and long-tail variations
    - **Search Volume**: Estimate monthly searches (Google Trends + predictive models)
    - **Competition Analysis**: Difficulty score (0-100) for ranking
    - **Search Intent**: Informational, Commercial, Transactional, Navigational
    - **SERP Analysis**: Current top 10 ranking pages
    - **Question Keywords**: "How to", "What is", "Best" variations
    - **Export to Quick Create**: Generate content targeting specific keywords

    ### How it will work:
    1. Enter seed keyword or topic
    2. AI generates 50-100 related keywords
    3. Filters by search volume and difficulty
    4. Ranks by opportunity score (volume / difficulty)
    5. Shows SERP features (featured snippets, PAA, images)
    6. Export top 10 keywords to Quick Create

    ### Data Sources:
    - Google Autocomplete (free, real-time suggestions)
    - Gemini Trends API (free, trending queries)
    - SearXNG (aggregated search volumes)
    - Manual SERP scraping (top 10 analysis)
    """)

    st.divider()

    # Placeholder inputs (non-functional)
    st.text_input(
        "Seed keyword",
        placeholder="e.g., property management software",
        help="Starting keyword for research",
        disabled=True
    )

    col1, col2 = st.columns(2)
    with col1:
        st.selectbox(
            "Language",
            ["German", "English", "French"],
            help="Target language for keywords",
            disabled=True
        )

    with col2:
        st.selectbox(
            "Market",
            ["Germany", "USA", "France"],
            help="Target geographic market",
            disabled=True
        )

    st.button("üîç Research Keywords", type="primary", use_container_width=True, disabled=True)


def render():
    """Render Topic Research Lab page with 3 tabs."""
    st.title("üî¨ Research Lab")
    st.caption("Comprehensive research tools: Deep topic research, competitor analysis, and SEO keyword discovery")

    # Render config sidebar (shared across all tabs)
    config = render_config_sidebar()

    st.divider()

    # Tab navigation
    tab1, tab2, tab3 = st.tabs([
        "üîç Topic Research",
        "üè¢ Competitor Analysis",
        "üîë Keyword Research"
    ])

    with tab1:
        render_topic_research_tab(config)

    with tab2:
        render_competitor_analysis_tab()

    with tab3:
        render_keyword_research_tab()
