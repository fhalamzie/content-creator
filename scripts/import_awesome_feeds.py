#!/usr/bin/env python3
"""
Import awesome-rss-feeds to database

Parses OPML files from awesome-rss-feeds GitHub repo and imports them
to our RSS feed database.

Usage:
    python scripts/import_awesome_feeds.py

This will:
1. Parse all OPML files from temp/awesome-rss-feeds/recommended/
2. Organize feeds into domains and verticals
3. Import to src/config/rss_feeds_database.json
4. Print statistics
"""

import asyncio
import os
import sys
from pathlib import Path
from typing import Dict, List

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.collectors.opml_parser import OPMLParser, OPMLFeed
from src.collectors.rss_feed_database import RSSFeedDatabase
from src.collectors.rss_feed_discoverer import RSSFeedDiscoverer, RSSFeed
from src.utils.logger import get_logger

logger = get_logger(__name__)


# Domain mapping: OPML category -> (domain, vertical)
DOMAIN_MAPPING = {
    # Technology domain
    "Tech": ("technology", "general"),
    "Startups": ("technology", "startups"),
    "Programming": ("technology", "programming"),
    "Web Development": ("technology", "web-development"),
    "Android Development": ("technology", "android-development"),
    "iOS Development": ("technology", "ios-development"),
    "Android": ("technology", "android"),
    "Apple": ("technology", "apple"),
    "UI - UX": ("technology", "ui-ux"),

    # Business domain
    "Business & Economy": ("business", "general"),
    "Personal finance": ("business", "personal-finance"),

    # Science domain
    "Science": ("science", "general"),
    "Space": ("science", "space"),

    # Lifestyle domain
    "Food": ("lifestyle", "food"),
    "Travel": ("lifestyle", "travel"),
    "Photography": ("lifestyle", "photography"),
    "Fashion": ("lifestyle", "fashion"),
    "Beauty": ("lifestyle", "beauty"),
    "Interior design": ("lifestyle", "interior-design"),
    "Architecture": ("lifestyle", "architecture"),
    "DIY": ("lifestyle", "diy"),

    # Entertainment domain
    "Movies": ("entertainment", "movies"),
    "Television": ("entertainment", "television"),
    "Music": ("entertainment", "music"),
    "Gaming": ("entertainment", "gaming"),
    "Funny": ("entertainment", "funny"),
    "Books": ("entertainment", "books"),

    # Sports domain
    "Sports": ("sports", "general"),
    "Football": ("sports", "football"),
    "Tennis": ("sports", "tennis"),
    "Cricket": ("sports", "cricket"),
    "Cars": ("sports", "cars"),

    # News domain
    "News": ("news", "general"),

    # History domain
    "History": ("education", "history"),
}


class AwesomeFeedsImporter:
    """Import awesome-rss-feeds to database."""

    def __init__(
        self,
        repo_path: str = "temp/awesome-rss-feeds",
        validate_feeds: bool = True
    ):
        """
        Initialize importer.

        Args:
            repo_path: Path to awesome-rss-feeds repo
            validate_feeds: Validate feeds before importing
        """
        self.repo_path = Path(repo_path)
        self.validate_feeds = validate_feeds

        self.parser = OPMLParser()
        self.database = RSSFeedDatabase()
        self.discoverer = RSSFeedDiscoverer() if validate_feeds else None

        # Statistics
        self.stats = {
            "files_processed": 0,
            "feeds_parsed": 0,
            "feeds_validated": 0,
            "feeds_imported": 0,
            "feeds_failed": 0,
            "feeds_duplicates": 0
        }

    def import_recommended_feeds(self):
        """Import feeds from recommended/ directory."""
        recommended_dir = self.repo_path / "recommended" / "with_category"

        if not recommended_dir.exists():
            logger.error("recommended_dir_not_found", path=str(recommended_dir))
            print(f"âŒ Error: {recommended_dir} not found")
            print(f"   Make sure awesome-rss-feeds repo is cloned to {self.repo_path}")
            return

        logger.info("import_started", path=str(recommended_dir))
        print(f"\nğŸ” Importing feeds from: {recommended_dir}\n")

        # Find all OPML files
        opml_files = list(recommended_dir.glob("*.opml"))
        print(f"Found {len(opml_files)} OPML files")

        # Parse each file
        for opml_file in opml_files:
            self._import_opml_file(opml_file)

        # Save database
        print(f"\nğŸ’¾ Saving database...")
        self.database.save()

        # Print statistics
        self._print_statistics()

    def _import_opml_file(self, file_path: Path):
        """
        Import feeds from a single OPML file.

        Args:
            file_path: Path to OPML file
        """
        category_name = file_path.stem  # Filename without extension
        print(f"\nğŸ“‚ Processing: {category_name}")

        # Parse OPML
        feeds = self.parser.parse_file(str(file_path))
        self.stats["files_processed"] += 1
        self.stats["feeds_parsed"] += len(feeds)

        print(f"   Found {len(feeds)} feeds")

        # Get domain and vertical
        domain, vertical = DOMAIN_MAPPING.get(category_name, ("uncategorized", category_name.lower()))

        # Import feeds
        imported_count = 0
        for opml_feed in feeds:
            success = self._import_feed(opml_feed, domain, vertical)
            if success:
                imported_count += 1

        print(f"   âœ… Imported {imported_count} feeds to {domain}/{vertical}")

    def _import_feed(self, opml_feed: OPMLFeed, domain: str, vertical: str) -> bool:
        """
        Import a single feed to database.

        Args:
            opml_feed: Parsed OPML feed
            domain: Domain category
            vertical: Vertical within domain

        Returns:
            True if imported, False otherwise
        """
        # Convert OPML feed to RSSFeed
        rss_feed = RSSFeed(
            url=opml_feed.url,
            source_url=opml_feed.website_url or opml_feed.url,
            title=opml_feed.title,
            description=opml_feed.description,
            discovery_method="opml",
            quality_score=0.0,  # Will be calculated if validation enabled
            is_valid=not self.validate_feeds  # Assume valid if not validating
        )

        # Validate feed if enabled
        if self.validate_feeds:
            # Note: Validation is async, but we're in sync context
            # For now, just import without validation to speed up
            # We'll add a separate validation step later
            rss_feed.quality_score = 0.5  # Default score for unvalidated feeds
            rss_feed.is_valid = True
            self.stats["feeds_validated"] += 1

        # Import to database
        added = self.database.add_feed(
            domain=domain,
            vertical=vertical,
            feed=rss_feed,
            allow_duplicates=False
        )

        if added:
            self.stats["feeds_imported"] += 1
            return True
        else:
            self.stats["feeds_duplicates"] += 1
            return False

    def _print_statistics(self):
        """Print import statistics."""
        print(f"\n" + "=" * 60)
        print(f"ğŸ“Š Import Statistics")
        print(f"=" * 60)
        print(f"Files processed:     {self.stats['files_processed']}")
        print(f"Feeds parsed:        {self.stats['feeds_parsed']}")
        print(f"Feeds imported:      {self.stats['feeds_imported']}")
        print(f"Duplicates skipped:  {self.stats['feeds_duplicates']}")
        if self.validate_feeds:
            print(f"Feeds validated:     {self.stats['feeds_validated']}")
            print(f"Validation failed:   {self.stats['feeds_failed']}")
        print(f"=" * 60)

        # Database statistics
        db_stats = self.database.get_statistics()
        print(f"\nğŸ“š Database Statistics")
        print(f"=" * 60)
        print(f"Total feeds:         {db_stats['total_feeds']}")
        print(f"Total domains:       {db_stats['total_domains']}")
        print(f"Total verticals:     {db_stats['total_verticals']}")
        print(f"=" * 60)

        # Per-domain statistics
        print(f"\nğŸ—‚ï¸  Feeds by Domain")
        print(f"=" * 60)
        for domain, stats in sorted(db_stats['domains'].items()):
            print(f"{domain:20} {stats['feeds']:4} feeds across {stats['verticals']:2} verticals")
        print(f"=" * 60)

        logger.info(
            "import_complete",
            stats=self.stats,
            db_stats=db_stats
        )


def main():
    """Main entry point."""
    print(f"\n{'=' * 60}")
    print(f"ğŸš€ Awesome RSS Feeds Importer")
    print(f"{'=' * 60}\n")

    # Initialize importer
    importer = AwesomeFeedsImporter(
        repo_path="temp/awesome-rss-feeds",
        validate_feeds=False  # Skip validation for speed (Phase 1)
    )

    # Import feeds
    importer.import_recommended_feeds()

    print(f"\nâœ… Import complete!")
    print(f"\nğŸ“„ Database saved to: {importer.database.database_path}")
    print(f"\nğŸ‰ You can now use these feeds in the RSS collector!\n")


if __name__ == "__main__":
    main()
